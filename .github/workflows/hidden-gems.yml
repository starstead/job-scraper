name: Auto-Add Hidden Gems to Companies CSV

on:
  workflow_dispatch:
    inputs:
      research_focus:
        description: 'Research Focus'
        required: true
        default: 'both'
        type: choice
        options:
        - anne
        - alessandro
        - both
      batch_size:
        description: 'Number of companies to discover'
        required: true
        default: '30'
        type: string
      auto_add_to_csv:
        description: 'Automatically add to companies_final_ready.csv'
        required: true
        default: true
        type: boolean

jobs:
  discover-and-add:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'
    
    - name: Install dependencies
      run: |
        pip install pandas beautifulsoup4 requests lxml html5lib python-dateutil
        pip install --upgrade urllib3 certifi
    
    - name: Create research directory
      run: mkdir -p research_results
    
    - name: Discover Hidden Gems and Auto-Add to CSV
      env:
        RESEARCH_FOCUS: ${{ github.event.inputs.research_focus }}
        BATCH_SIZE: ${{ github.event.inputs.batch_size }}
        AUTO_ADD_TO_CSV: ${{ github.event.inputs.auto_add_to_csv }}
      run: |
        python3 << 'EOF'
        import pandas as pd
        import requests
        from bs4 import BeautifulSoup
        import json
        import time
        import random
        import os
        from datetime import datetime
        import re
        from urllib.parse import urlparse
        
        # Configuration
        RESEARCH_FOCUS = os.environ.get('RESEARCH_FOCUS', 'both')
        BATCH_SIZE = int(os.environ.get('BATCH_SIZE', '30'))
        AUTO_ADD_TO_CSV = os.environ.get('AUTO_ADD_TO_CSV', 'true').lower() == 'true'
        
        print(f"üîç Automated Hidden Gems Discovery & CSV Integration")
        print(f"üéØ Focus: {RESEARCH_FOCUS}")
        print(f"üìä Target: {BATCH_SIZE} companies")
        print(f"üîÑ Auto-add to CSV: {AUTO_ADD_TO_CSV}")
        
        def generate_career_url(company_name):
            """Generate likely career page URL from company name"""
            # Clean company name for URL
            clean_name = re.sub(r'[^a-zA-Z0-9]', '', company_name.lower())
            
            # Common URL patterns
            patterns = [
                f"https://{clean_name}.com/careers",
                f"https://{clean_name}.com/jobs", 
                f"https://{clean_name}.com/careers/",
                f"https://careers.{clean_name}.com",
                f"https://jobs.{clean_name}.com",
                f"https://www.{clean_name}.com/careers",
                f"https://www.{clean_name}.com/jobs"
            ]
            
            # For compound names, try with hyphens
            if len(company_name.split()) > 1:
                hyphen_name = '-'.join(company_name.lower().split())
                patterns.extend([
                    f"https://{hyphen_name}.com/careers",
                    f"https://www.{hyphen_name}.com/careers"
                ])
            
            # Return the most likely URL (first pattern)
            return patterns[0]
        
        def generate_indeed_url(company_name):
            """Generate Indeed URL matching your CSV format"""
            return f'https://www.indeed.com/jobs?q=company:"{company_name}"&l=nan,CO'
        
        def generate_glassdoor_url(company_name):
            """Generate Glassdoor URL matching your CSV format"""
            clean_name = company_name.replace(' ', '-')
            return f'https://www.glassdoor.com/Jobs/{clean_name}-Jobs-E12345.htm'
        
        def discover_companies():
            """Discover companies with enhanced variety"""
            discovered = []
            
            print("üîç Discovering hidden gem companies...")
            
            # Source 1: Event Tech companies (Anne)
            if RESEARCH_FOCUS in ['anne', 'both']:
                anne_companies = [
                    # Event Tech
                    {'name': 'Hopin', 'industry': 'Virtual Events', 'size': '201-500', 'stage': 'Series C'},
                    {'name': 'Remo', 'industry': 'Virtual Events', 'size': '51-200', 'stage': 'Series A'},
                    {'name': 'Airmeet', 'industry': 'Virtual Events', 'size': '101-250', 'stage': 'Series A'},
                    {'name': 'BigMarker', 'industry': 'Webinar Platform', 'size': '51-200', 'stage': 'Bootstrap'},
                    {'name': 'Accelevents', 'industry': 'Event Management', 'size': '11-50', 'stage': 'Series A'},
                    {'name': 'EventMobi', 'industry': 'Event Apps', 'size': '51-200', 'stage': 'Series A'},
                    {'name': 'Ticket Tailor', 'industry': 'Event Ticketing', 'size': '11-50', 'stage': 'Bootstrap'},
                    {'name': 'Splash', 'industry': 'Event Marketing', 'size': '101-250', 'stage': 'Series B'},
                    {'name': 'Whova', 'industry': 'Event Management', 'size': '51-200', 'stage': 'Bootstrap'},
                    {'name': 'Run The World', 'industry': 'Virtual Events', 'size': '11-50', 'stage': 'Seed'},
                    
                    # MyLab-style platform companies
                    {'name': 'Pendo', 'industry': 'Product Analytics', 'size': '501-1000', 'stage': 'Series E'},
                    {'name': 'FullStory', 'industry': 'User Analytics', 'size': '201-500', 'stage': 'Series C'},
                    {'name': 'Mixpanel', 'industry': 'Product Analytics', 'size': '201-500', 'stage': 'Series B'},
                    {'name': 'Amplitude', 'industry': 'Product Analytics', 'size': '201-500', 'stage': 'Public'},
                    {'name': 'LaunchDarkly', 'industry': 'Feature Management', 'size': '201-500', 'stage': 'Series D'},
                    {'name': 'Optimizely', 'industry': 'Experimentation Platform', 'size': '501-1000', 'stage': 'Private Equity'},
                    {'name': 'UserTesting', 'industry': 'User Research', 'size': '501-1000', 'stage': 'Public'},
                    {'name': 'Hotjar', 'industry': 'User Analytics', 'size': '201-500', 'stage': 'Bootstrap'},
                    {'name': 'LogRocket', 'industry': 'User Analytics', 'size': '51-200', 'stage': 'Series B'},
                    {'name': 'PostHog', 'industry': 'Product Analytics', 'size': '51-200', 'stage': 'Series B'},
                    
                    # Customer Success & Onboarding platforms  
                    {'name': 'Gainsight', 'industry': 'Customer Success', 'size': '501-1000', 'stage': 'Private'},
                    {'name': 'ChurnZero', 'industry': 'Customer Success', 'size': '51-200', 'stage': 'Series A'},
                    {'name': 'Userpilot', 'industry': 'User Onboarding', 'size': '51-200', 'stage': 'Series A'},
                    {'name': 'Appcues', 'industry': 'User Onboarding', 'size': '51-200', 'stage': 'Series B'},
                    {'name': 'WalkMe', 'industry': 'Digital Adoption', 'size': '501-1000', 'stage': 'Public'},
                    {'name': 'Pendo', 'industry': 'Product Experience', 'size': '501-1000', 'stage': 'Series E'},
                ]
                
                discovered.extend(random.sample(anne_companies, min(len(anne_companies), BATCH_SIZE // 2)))
            
            # Source 2: Fintech & DefenseTech companies (Alessandro)
            if RESEARCH_FOCUS in ['alessandro', 'both']:
                alessandro_companies = [
                    # Fintech
                    {'name': 'Wise', 'industry': 'Cross-border Payments', 'size': '3000+', 'stage': 'Public'},
                    {'name': 'Remitly', 'industry': 'Remittances', 'size': '1001-5000', 'stage': 'Public'},
                    {'name': 'Nium', 'industry': 'Global Payments', 'size': '501-1000', 'stage': 'Series C'},
                    {'name': 'Thunes', 'industry': 'Cross-border Payments', 'size': '201-500', 'stage': 'Series B'},
                    {'name': 'Currencycloud', 'industry': 'Currency Exchange', 'size': '201-500', 'stage': 'Acquired'},
                    {'name': 'Mollie', 'industry': 'Payment Processing', 'size': '501-1000', 'stage': 'Series C'},
                    {'name': 'Checkout.com', 'industry': 'Payment Processing', 'size': '1001-5000', 'stage': 'Series C'},
                    {'name': 'Adyen', 'industry': 'Payment Processing', 'size': '5000+', 'stage': 'Public'},
                    {'name': 'Klarna', 'industry': 'BNPL Payments', 'size': '5000+', 'stage': 'Private'},
                    {'name': 'Revolut Business', 'industry': 'Business Banking', 'size': '2000+', 'stage': 'Series D'},
                    
                    # DefenseTech & GovTech
                    {'name': 'Palantir', 'industry': 'Government Software', 'size': '2000+', 'stage': 'Public'},
                    {'name': 'Anduril', 'industry': 'Defense Technology', 'size': '501-1000', 'stage': 'Series D'},
                    {'name': 'Shield AI', 'industry': 'Military AI', 'size': '201-500', 'stage': 'Series C'},
                    {'name': 'Rebellion Defense', 'industry': 'Defense Technology', 'size': '51-200', 'stage': 'Series B'},
                    {'name': 'Primer', 'industry': 'Government AI', 'size': '51-200', 'stage': 'Series A'},
                    {'name': 'Mark43', 'industry': 'Public Safety Tech', 'size': '201-500', 'stage': 'Series C'},
                    {'name': 'Axon', 'industry': 'Public Safety Tech', 'size': '1000+', 'stage': 'Public'},
                    {'name': 'Verint', 'industry': 'Security Intelligence', 'size': '5000+', 'stage': 'Public'},
                    {'name': 'Tyler Technologies', 'industry': 'Government Software', 'size': '5000+', 'stage': 'Public'},
                    {'name': 'Motorola Solutions', 'industry': 'Public Safety Tech', 'size': '10000+', 'stage': 'Public'},
                    
                    # Localization & International
                    {'name': 'Phrase', 'industry': 'Localization Platform', 'size': '201-500', 'stage': 'Series B'},
                    {'name': 'Lokalise', 'industry': 'Localization Platform', 'size': '101-250', 'stage': 'Series A'},
                    {'name': 'Smartling', 'industry': 'Translation Management', 'size': '201-500', 'stage': 'Series C'},
                    {'name': 'Transifex', 'industry': 'Localization Platform', 'size': '51-200', 'stage': 'Series A'},
                    {'name': 'Crowdin', 'industry': 'Localization Platform', 'size': '51-200', 'stage': 'Bootstrap'},
                ]
                
                discovered.extend(random.sample(alessandro_companies, min(len(alessandro_companies), BATCH_SIZE // 2)))
            
            # Ensure we have the right number
            if len(discovered) > BATCH_SIZE:
                discovered = random.sample(discovered, BATCH_SIZE)
            
            print(f"‚úÖ Discovered {len(discovered)} companies")
            return discovered
        
        # Discover companies
        companies = discover_companies()
        
        # Create DataFrame with enhanced data
        df = pd.DataFrame(companies)
        df['research_date'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        df['batch_id'] = f"batch_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        
        # Add MyLab/defense advantages
        def get_advantage(row):
            if RESEARCH_FOCUS == 'anne' or (RESEARCH_FOCUS == 'both' and 'Analytics' in row['industry']):
                return "Pearson MyLab platform experience directly applicable"
            elif RESEARCH_FOCUS == 'alessandro' or (RESEARCH_FOCUS == 'both' and any(term in row['industry'] for term in ['Defense', 'Public Safety', 'Government'])):
                return "Military/public safety experience valued"
            elif 'Localization' in row['industry']:
                return "International localization experience valued"
            else:
                return "Relevant platform/product experience"
        
        df['competitive_advantage'] = df.apply(get_advantage, axis=1)
        
        # Save discovery results
        discovery_file = 'research_results/hidden_gems_discovery.csv'
        df.to_csv(discovery_file, index=False)
        print(f"üìä Discovery results saved to {discovery_file}")
        
        # Auto-add to companies_final_ready.csv if enabled
        if AUTO_ADD_TO_CSV:
            print("\nüîÑ Auto-adding to companies_final_ready.csv...")
            
            try:
                # Load existing companies file
                existing_file = 'companies_final_ready.csv'
                if os.path.exists(existing_file):
                    existing_df = pd.read_csv(existing_file)
                    print(f"üìã Loaded {len(existing_df)} existing companies")
                else:
                    # Create new file with correct headers to match your CSV
                    existing_df = pd.DataFrame(columns=[
                        'Company', 'Industry', 'City', 'Careers Site URL', 'Company_Size', 
                        'Primary_Source', 'Indeed_URL', 'AngelList_URL', 'Glassdoor_URL', 'Backup_Strategy'
                    ])
                    print("üìã Creating new companies_final_ready.csv")
                
                # Get existing company names (case-insensitive)
                existing_names = set(existing_df['Company'].str.lower()) if not existing_df.empty else set()
                
                # Format new companies to match your CSV structure exactly
                new_companies = []
                for _, company in df.iterrows():
                    if company['name'].lower() not in existing_names:
                        # Map company size to your format
                        size_mapping = {
                            '11-50': 'Small',
                            '51-200': 'Medium', 
                            '101-250': 'Medium',
                            '201-500': 'Medium',
                            '501-1000': 'Large',
                            '1000+': 'Large',
                            '1001-5000': 'Large',
                            '2000+': 'Large',
                            '3000+': 'Large',
                            '5000+': 'Large',
                            '10000+': 'Large'
                        }
                        
                        company_size = size_mapping.get(company['size'], 'Medium')
                        
                        new_companies.append({
                            'Company': company['name'],
                            'Industry': company['industry'],
                            'City': '',  # Empty like your format
                            'Careers Site URL': generate_career_url(company['name']),
                            'Company_Size': company_size,
                            'Primary_Source': 'careers_page',
                            'Indeed_URL': generate_indeed_url(company['name']),
                            'AngelList_URL': '',  # Empty for now
                            'Glassdoor_URL': generate_glassdoor_url(company['name']),
                            'Backup_Strategy': 'careers_page,indeed'
                        })
                
                if new_companies:
                    # Add new companies
                    new_df = pd.DataFrame(new_companies)
                    combined_df = pd.concat([existing_df, new_df], ignore_index=True)
                    
                    # Save updated file
                    combined_df.to_csv(existing_file, index=False)
                    
                    print(f"‚úÖ Added {len(new_companies)} new companies to {existing_file}")
                    print(f"üìä Total companies now: {len(combined_df)}")
                    
                    # Show what was added
                    print("\nüéØ New companies added:")
                    for i, company in enumerate(new_companies, 1):
                        advantage = df[df['name'] == company['Company']]['competitive_advantage'].iloc[0]
                        print(f"{i:2d}. {company['Company']} ({company['Company_Size']})")
                        print(f"     üíº {company['Industry']}")
                        print(f"     üéØ {advantage}")
                        print(f"     üîó {company['Careers Site URL']}")
                        print()
                
                else:
                    print("‚ÑπÔ∏è  No new companies to add (all already exist)")
                
            except Exception as e:
                print(f"‚ùå Error updating CSV: {e}")
        
        # Create summary
        summary = {
            'discovery_info': {
                'research_focus': RESEARCH_FOCUS,
                'companies_discovered': len(companies),
                'auto_added_to_csv': AUTO_ADD_TO_CSV,
                'discovery_timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            },
            'company_breakdown': {
                'event_tech': len([c for c in companies if any(term in c['industry'] for term in ['Event', 'Virtual'])]),
                'analytics_platforms': len([c for c in companies if 'Analytics' in c['industry']]),
                'fintech': len([c for c in companies if any(term in c['industry'] for term in ['Payment', 'Banking', 'Fintech'])]),
                'defense_tech': len([c for c in companies if any(term in c['industry'] for term in ['Defense', 'Public Safety', 'Government'])]),
                'localization': len([c for c in companies if 'Localization' in c['industry']])
            },
            'top_targets': df.head(10)[['name', 'industry', 'size', 'stage', 'competitive_advantage']].to_dict('records')
        }
        
        summary_file = f"research_results/discovery_summary_{df['batch_id'].iloc[0] if not df.empty else 'empty'}.json"
        with open(summary_file, 'w') as f:
            json.dump(summary, f, indent=2)
        
        print(f"\nüéâ Automated Discovery & CSV Integration Complete!")
        print(f"üìä Companies discovered: {len(companies)}")
        if AUTO_ADD_TO_CSV:
            print(f"‚úÖ Successfully integrated with companies_final_ready.csv")
        print(f"üìã Summary saved to: {summary_file}")
        
        EOF
